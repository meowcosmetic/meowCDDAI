"""
Visualization functions - TÃ¡ch riÃªng drawing logic cho Gaze Tracking
"""
import cv2
import numpy as np
from typing import Optional, List, Dict, Any, Tuple


def draw_annotations(
    frame: np.ndarray,
    child_face: Optional[Any] = None,
    adult_face: Optional[Any] = None,
    gaze_dir: Optional[str] = None,
    detected_objects: Optional[List[Dict[str, Any]]] = None,
    is_focusing: bool = False,
    is_looking_at_adult: bool = False,
    is_looking_at_object: bool = False,
    frame_count: int = 0,
    fps: int = 30,
    gaze_x: Optional[float] = None,
    gaze_y: Optional[float] = None,
    head_pose: Optional[Tuple[float, float, float]] = None,
    variance: Optional[float] = None,
    rms_distance: Optional[float] = None,
    face_landmarks: Optional[Any] = None,
    show_landmarks: bool = False
) -> np.ndarray:
    """
    Váº½ cÃ¡c annotations lÃªn frame Ä‘á»ƒ hiá»ƒn thá»‹
    
    Args:
        frame: Frame cáº§n váº½
        child_face: Face cá»§a tráº» (list/tuple [x, y, width, height] hoáº·c dict)
        adult_face: Face cá»§a ngÆ°á»i lá»›n (list/tuple [x, y, width, height] hoáº·c dict)
        gaze_dir: HÆ°á»›ng nhÃ¬n ("left", "right", "center", "up", "down")
        detected_objects: Danh sÃ¡ch objects Ä‘Æ°á»£c detect
        is_focusing: Äang focusing hay khÃ´ng
        is_looking_at_adult: Äang nhÃ¬n vÃ o ngÆ°á»i lá»›n
        is_looking_at_object: Äang nhÃ¬n vÃ o object
        frame_count: Sá»‘ frame hiá»‡n táº¡i
        fps: FPS cá»§a video
        gaze_x: Tá»a Ä‘á»™ X cá»§a gaze (normalized offset, -1.0 Ä‘áº¿n 1.0)
        gaze_y: Tá»a Ä‘á»™ Y cá»§a gaze (normalized offset, -1.0 Ä‘áº¿n 1.0)
        head_pose: Tuple (yaw, pitch, roll) - hÆ°á»›ng quay Ä‘áº§u (radians)
        variance: Variance cá»§a gaze (legacy metric)
        rms_distance: RMS distance cá»§a gaze (improved metric)
        face_landmarks: MediaPipe face landmarks object
        show_landmarks: CÃ³ hiá»ƒn thá»‹ eye landmarks khÃ´ng (default: False)
    """
    h, w = frame.shape[:2]
    annotated_frame = frame.copy()
    
    # Váº½ MediaPipe eye landmarks náº¿u cÃ³
    if show_landmarks and face_landmarks is not None:
        try:
            # MediaPipe Face Mesh landmark indices
            LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
            RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
            LEFT_EYE_CENTER = 468  # Left iris center
            RIGHT_EYE_CENTER = 473  # Right iris center
            
            # Váº½ left eye landmarks (mÃ u xanh lÃ¡) - nhá» gá»n hÆ¡n
            for idx in LEFT_EYE_INDICES:
                if idx < len(face_landmarks.landmark):
                    lm = face_landmarks.landmark[idx]
                    x, y = int(lm.x * w), int(lm.y * h)
                    cv2.circle(annotated_frame, (x, y), 1, (0, 255, 0), -1)  # Green dots (smaller)
            
            # Váº½ right eye landmarks (mÃ u xanh dÆ°Æ¡ng) - nhá» gá»n hÆ¡n
            for idx in RIGHT_EYE_INDICES:
                if idx < len(face_landmarks.landmark):
                    lm = face_landmarks.landmark[idx]
                    x, y = int(lm.x * w), int(lm.y * h)
                    cv2.circle(annotated_frame, (x, y), 1, (255, 0, 0), -1)  # Blue dots (smaller)
            
            # Váº½ left eye center (iris) - mÃ u vÃ ng, nhá» gá»n hÆ¡n
            if LEFT_EYE_CENTER < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[LEFT_EYE_CENTER]
                x, y = int(lm.x * w), int(lm.y * h)
                cv2.circle(annotated_frame, (x, y), 2, (0, 255, 255), -1)  # Yellow (smaller)
                cv2.putText(annotated_frame, "L", (x + 4, y), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 255), 1)
            
            # Váº½ right eye center (iris) - mÃ u vÃ ng, nhá» gá»n hÆ¡n
            if RIGHT_EYE_CENTER < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[RIGHT_EYE_CENTER]
                x, y = int(lm.x * w), int(lm.y * h)
                cv2.circle(annotated_frame, (x, y), 2, (0, 255, 255), -1)  # Yellow (smaller)
                cv2.putText(annotated_frame, "R", (x + 4, y), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 255, 255), 1)
            
            # Váº½ outline cá»§a máº¯t (ná»‘i cÃ¡c Ä‘iá»ƒm landmarks)
            # Left eye outline
            if len(LEFT_EYE_INDICES) > 0:
                left_eye_points = []
                for idx in LEFT_EYE_INDICES[:8]:  # Láº¥y 8 Ä‘iá»ƒm Ä‘áº§u Ä‘á»ƒ váº½ outline
                    if idx < len(face_landmarks.landmark):
                        lm = face_landmarks.landmark[idx]
                        left_eye_points.append([int(lm.x * w), int(lm.y * h)])
                if len(left_eye_points) > 2:
                    cv2.polylines(annotated_frame, [np.array(left_eye_points, np.int32)], 
                                False, (0, 255, 0), 1)  # Green outline
            
            # Right eye outline
            if len(RIGHT_EYE_INDICES) > 0:
                right_eye_points = []
                for idx in RIGHT_EYE_INDICES[:8]:  # Láº¥y 8 Ä‘iá»ƒm Ä‘áº§u Ä‘á»ƒ váº½ outline
                    if idx < len(face_landmarks.landmark):
                        lm = face_landmarks.landmark[idx]
                        right_eye_points.append([int(lm.x * w), int(lm.y * h)])
                if len(right_eye_points) > 2:
                    cv2.polylines(annotated_frame, [np.array(right_eye_points, np.int32)], 
                                False, (255, 0, 0), 1)  # Blue outline
        except (AttributeError, IndexError, TypeError) as e:
            # Náº¿u face_landmarks khÃ´ng Ä‘Ãºng format, bá» qua
            pass
    
    # Váº½ face cá»§a tráº» (mÃ u xanh lÃ¡)
    if child_face is not None:
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            # OpenCV format: [x, y, width, height]
            x, y, w_face, h_face = child_face[:4]
            cv2.rectangle(annotated_frame, (int(x), int(y)), 
                         (int(x + w_face), int(y + h_face)), (0, 255, 0), 2)
            cv2.putText(annotated_frame, "Child", (int(x), int(y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_face), int(y + h_face)), (0, 255, 0), 2)
                cv2.putText(annotated_frame, "Child", (int(x), int(y) - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    # Váº½ face cá»§a ngÆ°á»i lá»›n (mÃ u xanh dÆ°Æ¡ng)
    if adult_face is not None:
        if isinstance(adult_face, (list, tuple)) and len(adult_face) >= 4:
            x, y, w_face, h_face = adult_face[:4]
            cv2.rectangle(annotated_frame, (int(x), int(y)), 
                         (int(x + w_face), int(y + h_face)), (255, 0, 0), 2)
            cv2.putText(annotated_frame, "Adult", (int(x), int(y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        elif isinstance(adult_face, dict):
            bbox = adult_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_face), int(y + h_face)), (255, 0, 0), 2)
                cv2.putText(annotated_frame, "Adult", (int(x), int(y) - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    
    # Váº½ gaze direction vector - sá»­ dá»¥ng gaze_x vÃ  gaze_y náº¿u cÃ³
    # LuÃ´n váº½ mÅ©i tÃªn náº¿u cÃ³ child_face hoáº·c gaze_dir
    should_draw_gaze = False
    face_center_x = w // 2
    face_center_y = h // 2
    
    if child_face is not None:
        should_draw_gaze = True
        # TÃ¬m tÃ¢m cá»§a khuÃ´n máº·t tráº»
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            x, y, w_face, h_face = child_face[:4]
            face_center_x = int(x + w_face / 2)
            face_center_y = int(y + h_face / 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                face_center_x = int(x + w_face / 2)
                face_center_y = int(y + h_face / 2)
    
    # Náº¿u khÃ´ng cÃ³ child_face nhÆ°ng cÃ³ gaze_dir, váº«n váº½ mÅ©i tÃªn á»Ÿ giá»¯a mÃ n hÃ¬nh
    if not should_draw_gaze and gaze_dir is not None:
        should_draw_gaze = True
    
    # Váº½ gaze vector dá»±a trÃªn gaze_x vÃ  gaze_y (náº¿u cÃ³)
    if should_draw_gaze and gaze_x is not None and gaze_y is not None:
        """
        GIáº¢I THÃCH Vá»€ GAZE MAGNITUDE:
        
        1. gaze_x vÃ  gaze_y lÃ  gÃ¬?
           - ÄÃ¢y lÃ  offset cá»§a con ngÆ°Æ¡i (iris) so vá»›i TÃ‚M Máº®T
           - CÃ´ng thá»©c: gaze_x = (iris_x - eye_center_x)
           - GiÃ¡ trá»‹ normalized trong há»‡ tá»a Ä‘á»™ MediaPipe (0.0-1.0)
        
        2. Táº¡i sao gaze_magnitude láº¡i NHá»?
           - Con ngÆ°Æ¡i chá»‰ di chuyá»ƒn má»™t khoáº£ng Ráº¤T NHá» trong máº¯t
           - Khi nhÃ¬n tháº³ng: iris á»Ÿ giá»¯a máº¯t â†’ offset â‰ˆ 0.0
           - Khi nhÃ¬n sang trÃ¡i/pháº£i: iris chá»‰ di chuyá»ƒn ~1-5% chiá»u rá»™ng máº¯t
           - Trong há»‡ normalized (0.0-1.0), offset thÆ°á»ng chá»‰ tá»« -0.05 Ä‘áº¿n 0.05
           - Váº­y nÃªn gaze_magnitude thÆ°á»ng ráº¥t nhá»: 0.001 - 0.05
        
        3. Gaze magnitude cÃ³ pháº£i hÆ°á»›ng nhÃ¬n khÃ´ng?
           - CÃ“, nhÆ°ng chá»‰ lÃ  hÆ°á»›ng TÆ¯Æ NG Äá»I trong máº¯t
           - KhÃ´ng pháº£i hÆ°á»›ng nhÃ¬n tuyá»‡t Ä‘á»‘i trong khÃ´ng gian 3D
           - Chá»‰ cho biáº¿t con ngÆ°Æ¡i Ä‘ang á»Ÿ Ä‘Ã¢u trong máº¯t:
             * gaze_x > 0: nhÃ¬n sang pháº£i (iris á»Ÿ bÃªn pháº£i tÃ¢m máº¯t)
             * gaze_x < 0: nhÃ¬n sang trÃ¡i (iris á»Ÿ bÃªn trÃ¡i tÃ¢m máº¯t)
             * gaze_y < 0: nhÃ¬n lÃªn trÃªn (iris á»Ÿ trÃªn tÃ¢m máº¯t)
             * gaze_y > 0: nhÃ¬n xuá»‘ng dÆ°á»›i (iris á»Ÿ dÆ°á»›i tÃ¢m máº¯t)
        
        4. Táº¡i sao cáº§n nhÃ¢n lÃªn?
           - Äá»ƒ hiá»ƒn thá»‹ mÅ©i tÃªn rÃµ rÃ ng trÃªn mÃ n hÃ¬nh
           - Magnitude nhá» â†’ mÅ©i tÃªn ngáº¯n â†’ khÃ³ nhÃ¬n tháº¥y
           - NhÃ¢n lÃªn 200 láº§n Ä‘á»ƒ phÃ³ng Ä‘áº¡i vÃ  dá»… quan sÃ¡t
        """
        
        # TÃ­nh Ä‘á»™ dÃ i thá»±c táº¿ cá»§a vector gaze (magnitude)
        gaze_magnitude = np.sqrt(gaze_x**2 + gaze_y**2)
        
        # Base length cho mÅ©i tÃªn (30% cá»§a kÃ­ch thÆ°á»›c nhá» hÆ¡n - nhá» hÆ¡n Ä‘á»ƒ tinh táº¿ hÆ¡n)
        base_length = min(w, h) * 0.3
        
        # Äá»™ dÃ i tá»‘i thiá»ƒu Ä‘á»ƒ mÅ©i tÃªn luÃ´n nhÃ¬n tháº¥y Ä‘Æ°á»£c (10% frame)
        min_arrow_length = min(w, h) * 0.1
        
        if gaze_magnitude < 0.01:
            # Náº¿u gaze quÃ¡ nhá» (< 0.01), nhÃ¢n lÃªn 200 láº§n Ä‘á»ƒ phÃ³ng Ä‘áº¡i
            # Äiá»u nÃ y giÃºp hiá»ƒn thá»‹ rÃµ rÃ ng ngay cáº£ khi nhÃ¬n tháº³ng
            amplified_gaze_x = gaze_x * 200
            amplified_gaze_y = gaze_y * 200
            amplified_magnitude = np.sqrt(amplified_gaze_x**2 + amplified_gaze_y**2)
            
            # Normalize Ä‘á»ƒ giá»¯ hÆ°á»›ng nhÆ°ng cÃ³ Ä‘á»™ dÃ i há»£p lÃ½
            if amplified_magnitude > 0:
                normalized_gaze_x = amplified_gaze_x / amplified_magnitude
                normalized_gaze_y = amplified_gaze_y / amplified_magnitude
            else:
                # Náº¿u váº«n báº±ng 0 sau khi nhÃ¢n, váº½ mÅ©i tÃªn nhá» lÃªn trÃªn
                normalized_gaze_x = 0
                normalized_gaze_y = -1
            
            # Äá»™ dÃ i mÅ©i tÃªn tá»« 15% Ä‘áº¿n 40% frame
            arrow_length = max(min_arrow_length, base_length * min(1.0, amplified_magnitude / 10))
            
            end_x = int(face_center_x + normalized_gaze_x * arrow_length)
            end_y = int(face_center_y + normalized_gaze_y * arrow_length)
        else:
            # Náº¿u magnitude Ä‘á»§ lá»›n (>= 0.01), sá»­ dá»¥ng giÃ¡ trá»‹ gá»‘c nhÆ°ng scale há»£p lÃ½
            # Normalize Ä‘á»ƒ giá»¯ hÆ°á»›ng
            normalized_gaze_x = gaze_x / gaze_magnitude if gaze_magnitude > 0 else 0
            normalized_gaze_y = gaze_y / gaze_magnitude if gaze_magnitude > 0 else 0
            
            # Äá»™ dÃ i mÅ©i tÃªn tá»· lá»‡ vá»›i magnitude nhÆ°ng cÃ³ minimum
            # Scale magnitude Ä‘á»ƒ mÅ©i tÃªn cÃ³ Ä‘á»™ dÃ i tá»« 15% Ä‘áº¿n 40% frame
            arrow_length = max(min_arrow_length, base_length * min(1.0, gaze_magnitude * 15))
            
            end_x = int(face_center_x + normalized_gaze_x * arrow_length)
            end_y = int(face_center_y + normalized_gaze_y * arrow_length)
        
        # Váº½ mÅ©i tÃªn gaze vector (mÃ u vÃ ng, má»ng hÆ¡n Ä‘á»ƒ giá»‘ng cÃ¡c annotation khÃ¡c)
        cv2.arrowedLine(annotated_frame, (face_center_x, face_center_y),
                       (end_x, end_y), (0, 255, 255), 2, tipLength=0.2, line_type=cv2.LINE_AA)
        
        # Váº½ Ä‘iá»ƒm báº¯t Ä‘áº§u (máº¯t) - vÃ²ng trÃ²n nhá» hÆ¡n
        cv2.circle(annotated_frame, (face_center_x, face_center_y), 3, (0, 255, 255), -1)
        
        # Hiá»ƒn thá»‹ thÃ´ng tin gaze (font nhá» hÆ¡n)
        gaze_info = f"Gaze: ({gaze_x:.3f}, {gaze_y:.3f})"
        if gaze_dir:
            gaze_info += f" [{gaze_dir}]"
        cv2.putText(annotated_frame, gaze_info, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
    elif should_draw_gaze and gaze_dir is not None:
        # Fallback: sá»­ dá»¥ng gaze_dir náº¿u khÃ´ng cÃ³ gaze_x/gaze_y
        arrow_length = min(w, h) * 0.25  # TÄƒng Ä‘á»™ dÃ i mÅ©i tÃªn
        if gaze_dir == "left":
            end_x = face_center_x - int(arrow_length)
            end_y = face_center_y
        elif gaze_dir == "right":
            end_x = face_center_x + int(arrow_length)
            end_y = face_center_y
        elif gaze_dir == "up":
            end_x = face_center_x
            end_y = face_center_y - int(arrow_length)
        elif gaze_dir == "down":
            end_x = face_center_x
            end_y = face_center_y + int(arrow_length)
        else:  # center
            # Váº½ mÅ©i tÃªn nhá» lÃªn trÃªn Ä‘á»ƒ chá»‰ ra Ä‘ang nhÃ¬n tháº³ng
            end_x = face_center_x
            end_y = face_center_y - int(arrow_length * 0.3)
        
        cv2.arrowedLine(annotated_frame, (face_center_x, face_center_y),
                       (end_x, end_y), (0, 255, 255), 2, tipLength=0.2, line_type=cv2.LINE_AA)
        cv2.circle(annotated_frame, (face_center_x, face_center_y), 3, (0, 255, 255), -1)
        cv2.putText(annotated_frame, f"Gaze: {gaze_dir}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
    
    # Váº½ detected objects - Táº¤T Cáº¢ objects, khÃ´ng chá»‰ sÃ¡ch
    if detected_objects:
        # Váº½ táº¥t cáº£ objects vá»›i bounding boxes
        for obj in detected_objects:
            obj_class = obj.get('class', 'unknown')
            bbox = obj.get('bbox', [])
            confidence = obj.get('confidence', 0)
            track_id = obj.get('track_id')  # Track ID náº¿u cÃ³
            
            if len(bbox) >= 4:
                x, y, w_obj, h_obj = bbox[:4]
                
                # MÃ u khÃ¡c nhau cho tá»«ng loáº¡i object
                if obj_class == 'book':
                    color = (0, 255, 255)  # Cyan - highlight sÃ¡ch
                    thickness = 3
                    emoji = "ğŸ“–"
                elif obj_class == 'person':
                    color = (255, 165, 0)  # Orange
                    thickness = 2
                    emoji = "ğŸ‘¤"
                elif obj_class == 'cup':
                    color = (255, 0, 255)  # Magenta
                    thickness = 2
                    emoji = "â˜•"
                elif obj_class == 'bottle':
                    color = (0, 255, 0)  # Green
                    thickness = 2
                    emoji = "ğŸ¼"
                elif obj_class == 'cell phone':
                    color = (255, 255, 0)  # Yellow
                    thickness = 2
                    emoji = "ğŸ“±"
                elif obj_class == 'laptop':
                    color = (128, 0, 128)  # Purple
                    thickness = 2
                    emoji = "ğŸ’»"
                elif obj_class in ['pen', 'pencil', 'marker', 'crayon']:  # âœ… OID cÃ³ pen/pencil!
                    color = (0, 255, 255)  # Cyan
                    thickness = 2
                    emoji = "ğŸ–Šï¸"
                elif obj_class in ['scissors', 'knife']:
                    color = (255, 200, 0)  # Orange-yellow
                    thickness = 2
                    emoji = "âœ‚ï¸"
                elif obj_class in ['toothbrush', 'hair drier']:
                    color = (128, 128, 128)  # Gray
                    thickness = 2
                    emoji = "ğŸ“¦"
                elif obj_class == 'remote':
                    color = (128, 128, 0)  # Olive
                    thickness = 2
                    emoji = "ğŸ“º"
                elif obj_class == 'mouse':
                    color = (0, 128, 255)  # Orange
                    thickness = 2
                    emoji = "ğŸ–±ï¸"
                elif obj_class == 'keyboard':
                    color = (255, 128, 0)  # Orange
                    thickness = 2
                    emoji = "âŒ¨ï¸"
                else:
                    # âœ… Táº¤T Cáº¢ objects khÃ¡c Ä‘á»u Ä‘Æ°á»£c hiá»ƒn thá»‹
                    color = (255, 0, 255)  # Magenta - default
                    thickness = 2
                    emoji = "ğŸ“¦"
                
                # Váº½ bounding box
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_obj), int(y + h_obj)), color, thickness)
                
                # Label vá»›i emoji, class name, confidence vÃ  track_id
                label = f"{emoji} {obj_class}"
                if track_id is not None:
                    label += f" ID:{track_id}"
                label += f" {confidence:.2f}"
                
                # Váº½ label vá»›i background Ä‘á»ƒ dá»… Ä‘á»c
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, thickness
                )
                cv2.rectangle(annotated_frame, 
                             (int(x), int(y) - text_height - 10),
                             (int(x) + text_width, int(y)),
                             color, -1)  # Filled rectangle
                cv2.putText(annotated_frame, label, (int(x), int(y) - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), thickness)  # Black text
    
    # Váº½ status bar á»Ÿ trÃªn cÃ¹ng
    status_y = 20
    status_color = (0, 255, 0) if is_focusing else (0, 0, 255)
    status_text = "FOCUSING" if is_focusing else "NOT FOCUSING"
    cv2.rectangle(annotated_frame, (10, 5), (w - 10, 35), (0, 0, 0), -1)
    cv2.putText(annotated_frame, status_text, (20, 25),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
    
    # Váº½ thÃ´ng tin attention
    info_y = 60
    if is_looking_at_adult:
        cv2.putText(annotated_frame, "Looking at Adult", (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        info_y += 25
    if is_looking_at_object:
        cv2.putText(annotated_frame, "Looking at Object", (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        info_y += 25
    
    # Váº½ frame count vÃ  time
    if fps > 0:
        time_sec = frame_count / fps
        time_text = f"Frame: {frame_count} | Time: {time_sec:.2f}s"
        cv2.putText(annotated_frame, time_text, (10, h - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # Váº½ hÆ°á»›ng dáº«n dá»«ng (á»Ÿ gÃ³c trÃªn bÃªn pháº£i)
    stop_text = "Press 'q' or ESC to stop"
    text_size = cv2.getTextSize(stop_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
    text_x = w - text_size[0] - 10
    text_y = 25
    # Background cho text
    cv2.rectangle(annotated_frame, 
                 (text_x - 5, text_y - text_size[1] - 5),
                 (text_x + text_size[0] + 5, text_y + 5),
                 (0, 0, 0), -1)  # Black background
    cv2.putText(annotated_frame, stop_text, (text_x, text_y),
               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)  # Cyan text
    
    # Váº½ vá»‹ trÃ­ gaze (gaze_x, gaze_y) náº¿u cÃ³
    if gaze_x is not None and gaze_y is not None:
        # Hiá»ƒn thá»‹ giÃ¡ trá»‹ gaze_x vÃ  gaze_y
        gaze_text = f"Gaze: X={gaze_x:.3f}, Y={gaze_y:.3f}"
        text_x = 10
        text_y = h - 40  # á» trÃªn dÃ²ng time
        
        # Váº½ background cho text Ä‘á»ƒ dá»… Ä‘á»c
        (text_width, text_height), baseline = cv2.getTextSize(
            gaze_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )
        cv2.rectangle(annotated_frame, 
                     (text_x - 5, text_y - text_height - 5),
                     (text_x + text_width + 5, text_y + 5),
                     (0, 0, 0), -1)  # Black background
        
        # Váº½ text
        cv2.putText(annotated_frame, gaze_text, (text_x, text_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)  # Cyan color
        
        # Váº½ crosshair táº¡i vá»‹ trÃ­ gaze trÃªn frame (chá»‰ khi cÃ³ child_face)
        if child_face is not None:
            if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
                x_face, y_face, w_face, h_face = child_face[:4]
                face_center_x = int(x_face + w_face / 2)
                face_center_y = int(y_face + h_face / 2)
            elif isinstance(child_face, dict):
                bbox = child_face.get('bbox', [])
                if len(bbox) >= 4:
                    x_face, y_face, w_face, h_face = bbox[:4]
                    face_center_x = int(x_face + w_face / 2)
                    face_center_y = int(y_face + h_face / 2)
                else:
                    face_center_x = w // 2
                    face_center_y = h // 2
                    w_face, h_face = w * 0.3, h * 0.3
            else:
                face_center_x = w // 2
                face_center_y = h // 2
                w_face, h_face = w * 0.3, h * 0.3

            # TÃ­nh vá»‹ trÃ­ gaze hiá»ƒn thá»‹ trÃªn frame (tá»« gaze_x/gaze_y)
            # LÆ°u Ã½: gaze_x/gaze_y lÃ  offset Ä‘Ã£ chuáº©n hoÃ¡ theo KÃCH THÆ¯á»šC Máº®T (khÃ´ng pháº£i theo frame).
            # VÃ¬ váº­y khi váº½, scale theo kÃ­ch thÆ°á»›c khuÃ´n máº·t Ä‘á»ƒ trá»±c quan hÆ¡n vÃ  trÃ¡nh â€œbáº¯nâ€ ra xa.
            scale_x = max(40, int(w_face * 0.9))
            scale_y = max(40, int(h_face * 0.9))

            gaze_pixel_x = int(face_center_x + gaze_x * scale_x)
            gaze_pixel_y = int(face_center_y + gaze_y * scale_y)

            # Äáº£m báº£o trong frame bounds
            gaze_pixel_x = max(0, min(w - 1, gaze_pixel_x))
            gaze_pixel_y = max(0, min(h - 1, gaze_pixel_y))

            # Váº½ crosshair (dáº¥u +) táº¡i vá»‹ trÃ­ gaze
            crosshair_size = 15
            # Äiá»ƒm nhÃ¬n (crosshair) dÃ¹ng mÃ u khÃ¡c Ä‘á»ƒ phÃ¢n biá»‡t vá»›i mÅ©i tÃªn gaze (mÃ u vÃ ng)
            crosshair_color = (255, 0, 255)  # Magenta
            crosshair_thickness = 2

            # Váº½ Ä‘Æ°á»ng ngang
            cv2.line(
                annotated_frame,
                (gaze_pixel_x - crosshair_size, gaze_pixel_y),
                (gaze_pixel_x + crosshair_size, gaze_pixel_y),
                crosshair_color,
                crosshair_thickness,
            )
            # Váº½ Ä‘Æ°á»ng dá»c
            cv2.line(
                annotated_frame,
                (gaze_pixel_x, gaze_pixel_y - crosshair_size),
                (gaze_pixel_x, gaze_pixel_y + crosshair_size),
                crosshair_color,
                crosshair_thickness,
            )

            # Váº½ Ä‘iá»ƒm trÃ²n táº¡i vá»‹ trÃ­ gaze
            cv2.circle(annotated_frame, (gaze_pixel_x, gaze_pixel_y), 5, crosshair_color, -1)

            # Váº½ Ä‘Æ°á»ng ná»‘i tá»« face center Ä‘áº¿n gaze position (cÃ¹ng mÃ u vá»›i Ä‘iá»ƒm nhÃ¬n)
            cv2.line(
                annotated_frame,
                (face_center_x, face_center_y),
                (gaze_pixel_x, gaze_pixel_y),
                crosshair_color,
                2,
            )  # Yellow line
    
    # Váº½ hÆ°á»›ng quay Ä‘áº§u (head rotation) náº¿u cÃ³
    if child_face is not None and head_pose is not None:
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            x, y, w_face, h_face = child_face[:4]
            face_center_x = int(x + w_face / 2)
            face_center_y = int(y + h_face / 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                face_center_x = int(x + w_face / 2)
                face_center_y = int(y + h_face / 2)
            else:
                face_center_x = w // 2
                face_center_y = h // 2
        else:
            face_center_x = w // 2
            face_center_y = h // 2
        
        try:
            yaw, pitch, roll = head_pose
            
            # Chuyá»ƒn Ä‘á»•i tá»« radians sang degrees Ä‘á»ƒ hiá»ƒn thá»‹
            yaw_deg = np.degrees(yaw)
            pitch_deg = np.degrees(pitch)
            roll_deg = np.degrees(roll)
            
            # TÃ­nh hÆ°á»›ng quay Ä‘áº§u dá»±a trÃªn yaw vÃ  pitch
            # Arrow length tá»· lá»‡ vá»›i gÃ³c quay
            max_angle = 30.0  # degrees
            arrow_length_base = 60
            
            # Yaw (left/right rotation)
            yaw_ratio = np.clip(abs(yaw_deg) / max_angle, 0, 1)
            yaw_arrow_length = int(arrow_length_base * yaw_ratio)
            if abs(yaw_deg) > 2:  # Chá»‰ váº½ náº¿u quay Ä‘Ã¡ng ká»ƒ (>2 Ä‘á»™)
                if yaw_deg < 0:  # Quay trÃ¡i
                    yaw_end_x = face_center_x - yaw_arrow_length
                    yaw_end_y = face_center_y
                else:  # Quay pháº£i
                    yaw_end_x = face_center_x + yaw_arrow_length
                    yaw_end_y = face_center_y
                
                # Váº½ arrow cho yaw (mÃ u Ä‘á»)
                cv2.arrowedLine(annotated_frame, 
                               (face_center_x, face_center_y),
                               (yaw_end_x, yaw_end_y),
                               (0, 0, 255), 2, tipLength=0.3)
            
            # Pitch (up/down rotation)
            pitch_ratio = np.clip(abs(pitch_deg) / max_angle, 0, 1)
            pitch_arrow_length = int(arrow_length_base * pitch_ratio)
            if abs(pitch_deg) > 2:  # Chá»‰ váº½ náº¿u quay Ä‘Ã¡ng ká»ƒ (>2 Ä‘á»™)
                # Vá»›i cÃ¡ch tÃ­nh pitch hiá»‡n táº¡i trong processor, pitch Ã¢m thÆ°á»ng tÆ°Æ¡ng á»©ng â€œcÃºi xuá»‘ngâ€.
                if pitch_deg < 0:  # Quay xuá»‘ng
                    pitch_end_x = face_center_x
                    pitch_end_y = face_center_y + pitch_arrow_length
                else:  # Quay lÃªn
                    pitch_end_x = face_center_x
                    pitch_end_y = face_center_y - pitch_arrow_length
                
                # Váº½ arrow cho pitch (mÃ u xanh lÃ¡)
                cv2.arrowedLine(annotated_frame,
                               (face_center_x, face_center_y),
                               (pitch_end_x, pitch_end_y),
                               (0, 255, 0), 2, tipLength=0.3)
            
            # Hiá»ƒn thá»‹ thÃ´ng tin head pose
            head_pose_text = f"Head: Yaw={yaw_deg:.1f}Â° Pitch={pitch_deg:.1f}Â° Roll={roll_deg:.1f}Â°"
            text_x = 10
            text_y = 90  # á» dÆ°á»›i gaze direction text
            
            # Váº½ background cho text
            (text_width, text_height), baseline = cv2.getTextSize(
                head_pose_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            cv2.rectangle(annotated_frame,
                         (text_x - 5, text_y - text_height - 5),
                         (text_x + text_width + 5, text_y + 5),
                         (0, 0, 0), -1)  # Black background
            
            # Váº½ text
            cv2.putText(annotated_frame, head_pose_text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)  # White color
            
            # Váº½ legend cho head rotation arrows
            legend_y = text_y + 25
            cv2.putText(annotated_frame, "Red: Yaw (L/R)", (text_x, legend_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            cv2.putText(annotated_frame, "Green: Pitch (U/D)", (text_x, legend_y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
        except (ValueError, TypeError) as e:
            # Náº¿u head_pose khÃ´ng Ä‘Ãºng format, bá» qua
            pass
    
    # Váº½ variance vÃ  RMS distance náº¿u cÃ³
    stats_y = h - 70  # á» trÃªn gaze text
    stats_texts = []
    
    if variance is not None:
        stats_texts.append(f"Variance: {variance:.6f}")
    
    if rms_distance is not None:
        stats_texts.append(f"RMS: {rms_distance:.6f}")
    
    if stats_texts:
        stats_text = " | ".join(stats_texts)
        text_x = 10
        
        # Váº½ background cho text
        (text_width, text_height), baseline = cv2.getTextSize(
            stats_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        cv2.rectangle(annotated_frame,
                     (text_x - 5, stats_y - text_height - 5),
                     (text_x + text_width + 5, stats_y + 5),
                     (0, 0, 0), -1)  # Black background
        
        # Váº½ text
        cv2.putText(annotated_frame, stats_text, (text_x, stats_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)  # Yellow color
    
    return annotated_frame
