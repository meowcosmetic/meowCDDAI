"""
Visualization functions - T√°ch ri√™ng drawing logic cho Gaze Tracking
"""
import cv2
import numpy as np
from typing import Optional, List, Dict, Any, Tuple


def draw_annotations(
    frame: np.ndarray,
    child_face: Optional[Any] = None,
    adult_face: Optional[Any] = None,
    gaze_dir: Optional[str] = None,
    detected_objects: Optional[List[Dict[str, Any]]] = None,
    is_focusing: bool = False,
    is_looking_at_adult: bool = False,
    is_looking_at_object: bool = False,
    frame_count: int = 0,
    fps: int = 30,
    gaze_x: Optional[float] = None,
    gaze_y: Optional[float] = None,
    head_pose: Optional[Tuple[float, float, float]] = None,
    variance: Optional[float] = None,
    rms_distance: Optional[float] = None,
    face_landmarks: Optional[Any] = None,
    show_landmarks: bool = False
) -> np.ndarray:
    """
    V·∫Ω c√°c annotations l√™n frame ƒë·ªÉ hi·ªÉn th·ªã
    
    Args:
        frame: Frame c·∫ßn v·∫Ω
        child_face: Face c·ªßa tr·∫ª (list/tuple [x, y, width, height] ho·∫∑c dict)
        adult_face: Face c·ªßa ng∆∞·ªùi l·ªõn (list/tuple [x, y, width, height] ho·∫∑c dict)
        gaze_dir: H∆∞·ªõng nh√¨n ("left", "right", "center", "up", "down")
        detected_objects: Danh s√°ch objects ƒë∆∞·ª£c detect
        is_focusing: ƒêang focusing hay kh√¥ng
        is_looking_at_adult: ƒêang nh√¨n v√†o ng∆∞·ªùi l·ªõn
        is_looking_at_object: ƒêang nh√¨n v√†o object
        frame_count: S·ªë frame hi·ªán t·∫°i
        fps: FPS c·ªßa video
        gaze_x: T·ªça ƒë·ªô X c·ªßa gaze (normalized offset, -1.0 ƒë·∫øn 1.0)
        gaze_y: T·ªça ƒë·ªô Y c·ªßa gaze (normalized offset, -1.0 ƒë·∫øn 1.0)
        head_pose: Tuple (yaw, pitch, roll) - h∆∞·ªõng quay ƒë·∫ßu (radians)
        variance: Variance c·ªßa gaze (legacy metric)
        rms_distance: RMS distance c·ªßa gaze (improved metric)
        face_landmarks: MediaPipe face landmarks object
        show_landmarks: C√≥ hi·ªÉn th·ªã eye landmarks kh√¥ng (default: False)
    """
    h, w = frame.shape[:2]
    annotated_frame = frame.copy()
    
    # V·∫Ω MediaPipe eye landmarks n·∫øu c√≥
    if show_landmarks and face_landmarks is not None:
        try:
            # MediaPipe Face Mesh landmark indices
            LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
            RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
            LEFT_EYE_CENTER = 468  # Left iris center
            RIGHT_EYE_CENTER = 473  # Right iris center
            
            # V·∫Ω left eye landmarks (m√†u xanh l√°)
            for idx in LEFT_EYE_INDICES:
                if idx < len(face_landmarks.landmark):
                    lm = face_landmarks.landmark[idx]
                    x, y = int(lm.x * w), int(lm.y * h)
                    cv2.circle(annotated_frame, (x, y), 2, (0, 255, 0), -1)  # Green dots
            
            # V·∫Ω right eye landmarks (m√†u xanh d∆∞∆°ng)
            for idx in RIGHT_EYE_INDICES:
                if idx < len(face_landmarks.landmark):
                    lm = face_landmarks.landmark[idx]
                    x, y = int(lm.x * w), int(lm.y * h)
                    cv2.circle(annotated_frame, (x, y), 2, (255, 0, 0), -1)  # Blue dots
            
            # V·∫Ω left eye center (iris) - m√†u v√†ng, l·ªõn h∆°n
            if LEFT_EYE_CENTER < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[LEFT_EYE_CENTER]
                x, y = int(lm.x * w), int(lm.y * h)
                cv2.circle(annotated_frame, (x, y), 4, (0, 255, 255), -1)  # Yellow, larger
                cv2.putText(annotated_frame, "L", (x + 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
            
            # V·∫Ω right eye center (iris) - m√†u v√†ng, l·ªõn h∆°n
            if RIGHT_EYE_CENTER < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[RIGHT_EYE_CENTER]
                x, y = int(lm.x * w), int(lm.y * h)
                cv2.circle(annotated_frame, (x, y), 4, (0, 255, 255), -1)  # Yellow, larger
                cv2.putText(annotated_frame, "R", (x + 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
            
            # V·∫Ω outline c·ªßa m·∫Øt (n·ªëi c√°c ƒëi·ªÉm landmarks)
            # Left eye outline
            if len(LEFT_EYE_INDICES) > 0:
                left_eye_points = []
                for idx in LEFT_EYE_INDICES[:8]:  # L·∫•y 8 ƒëi·ªÉm ƒë·∫ßu ƒë·ªÉ v·∫Ω outline
                    if idx < len(face_landmarks.landmark):
                        lm = face_landmarks.landmark[idx]
                        left_eye_points.append([int(lm.x * w), int(lm.y * h)])
                if len(left_eye_points) > 2:
                    cv2.polylines(annotated_frame, [np.array(left_eye_points, np.int32)], 
                                False, (0, 255, 0), 1)  # Green outline
            
            # Right eye outline
            if len(RIGHT_EYE_INDICES) > 0:
                right_eye_points = []
                for idx in RIGHT_EYE_INDICES[:8]:  # L·∫•y 8 ƒëi·ªÉm ƒë·∫ßu ƒë·ªÉ v·∫Ω outline
                    if idx < len(face_landmarks.landmark):
                        lm = face_landmarks.landmark[idx]
                        right_eye_points.append([int(lm.x * w), int(lm.y * h)])
                if len(right_eye_points) > 2:
                    cv2.polylines(annotated_frame, [np.array(right_eye_points, np.int32)], 
                                False, (255, 0, 0), 1)  # Blue outline
        except (AttributeError, IndexError, TypeError) as e:
            # N·∫øu face_landmarks kh√¥ng ƒë√∫ng format, b·ªè qua
            pass
    
    # V·∫Ω face c·ªßa tr·∫ª (m√†u xanh l√°)
    if child_face is not None:
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            # OpenCV format: [x, y, width, height]
            x, y, w_face, h_face = child_face[:4]
            cv2.rectangle(annotated_frame, (int(x), int(y)), 
                         (int(x + w_face), int(y + h_face)), (0, 255, 0), 2)
            cv2.putText(annotated_frame, "Child", (int(x), int(y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_face), int(y + h_face)), (0, 255, 0), 2)
                cv2.putText(annotated_frame, "Child", (int(x), int(y) - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    # V·∫Ω face c·ªßa ng∆∞·ªùi l·ªõn (m√†u xanh d∆∞∆°ng)
    if adult_face is not None:
        if isinstance(adult_face, (list, tuple)) and len(adult_face) >= 4:
            x, y, w_face, h_face = adult_face[:4]
            cv2.rectangle(annotated_frame, (int(x), int(y)), 
                         (int(x + w_face), int(y + h_face)), (255, 0, 0), 2)
            cv2.putText(annotated_frame, "Adult", (int(x), int(y) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        elif isinstance(adult_face, dict):
            bbox = adult_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_face), int(y + h_face)), (255, 0, 0), 2)
                cv2.putText(annotated_frame, "Adult", (int(x), int(y) - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    
    # V·∫Ω gaze direction arrow
    if child_face is not None and gaze_dir is not None:
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            x, y, w_face, h_face = child_face[:4]
            face_center_x = int(x + w_face / 2)
            face_center_y = int(y + h_face / 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                face_center_x = int(x + w_face / 2)
                face_center_y = int(y + h_face / 2)
            else:
                face_center_x = w // 2
                face_center_y = h // 2
        else:
            face_center_x = w // 2
            face_center_y = h // 2
        
        # T√≠nh v·ªã tr√≠ m≈©i t√™n d·ª±a tr√™n gaze direction
        arrow_length = 50
        if gaze_dir == "left":
            end_x = face_center_x - arrow_length
            end_y = face_center_y
        elif gaze_dir == "right":
            end_x = face_center_x + arrow_length
            end_y = face_center_y
        elif gaze_dir == "up":
            end_x = face_center_x
            end_y = face_center_y - arrow_length
        elif gaze_dir == "down":
            end_x = face_center_x
            end_y = face_center_y + arrow_length
        else:  # center
            end_x = face_center_x
            end_y = face_center_y
        
        cv2.arrowedLine(annotated_frame, (face_center_x, face_center_y),
                       (end_x, end_y), (0, 255, 255), 3, tipLength=0.3)
        cv2.putText(annotated_frame, f"Gaze: {gaze_dir}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    
    # V·∫Ω detected objects - T·∫§T C·∫¢ objects, kh√¥ng ch·ªâ s√°ch
    if detected_objects:
        # V·∫Ω t·∫•t c·∫£ objects v·ªõi bounding boxes
        for obj in detected_objects:
            obj_class = obj.get('class', 'unknown')
            bbox = obj.get('bbox', [])
            confidence = obj.get('confidence', 0)
            track_id = obj.get('track_id')  # Track ID n·∫øu c√≥
            
            if len(bbox) >= 4:
                x, y, w_obj, h_obj = bbox[:4]
                
                # M√†u kh√°c nhau cho t·ª´ng lo·∫°i object
                if obj_class == 'book':
                    color = (0, 255, 255)  # Cyan - highlight s√°ch
                    thickness = 3
                    emoji = "üìñ"
                elif obj_class == 'person':
                    color = (255, 165, 0)  # Orange
                    thickness = 2
                    emoji = "üë§"
                elif obj_class == 'cup':
                    color = (255, 0, 255)  # Magenta
                    thickness = 2
                    emoji = "‚òï"
                elif obj_class == 'bottle':
                    color = (0, 255, 0)  # Green
                    thickness = 2
                    emoji = "üçº"
                elif obj_class == 'cell phone':
                    color = (255, 255, 0)  # Yellow
                    thickness = 2
                    emoji = "üì±"
                elif obj_class == 'laptop':
                    color = (128, 0, 128)  # Purple
                    thickness = 2
                    emoji = "üíª"
                elif obj_class in ['pen', 'pencil', 'marker', 'crayon']:  # ‚úÖ OID c√≥ pen/pencil!
                    color = (0, 255, 255)  # Cyan
                    thickness = 2
                    emoji = "üñäÔ∏è"
                elif obj_class in ['scissors', 'knife']:
                    color = (255, 200, 0)  # Orange-yellow
                    thickness = 2
                    emoji = "‚úÇÔ∏è"
                elif obj_class in ['toothbrush', 'hair drier']:
                    color = (128, 128, 128)  # Gray
                    thickness = 2
                    emoji = "üì¶"
                elif obj_class == 'remote':
                    color = (128, 128, 0)  # Olive
                    thickness = 2
                    emoji = "üì∫"
                elif obj_class == 'mouse':
                    color = (0, 128, 255)  # Orange
                    thickness = 2
                    emoji = "üñ±Ô∏è"
                elif obj_class == 'keyboard':
                    color = (255, 128, 0)  # Orange
                    thickness = 2
                    emoji = "‚å®Ô∏è"
                else:
                    # ‚úÖ T·∫§T C·∫¢ objects kh√°c ƒë·ªÅu ƒë∆∞·ª£c hi·ªÉn th·ªã
                    color = (255, 0, 255)  # Magenta - default
                    thickness = 2
                    emoji = "üì¶"
                
                # V·∫Ω bounding box
                cv2.rectangle(annotated_frame, (int(x), int(y)), 
                             (int(x + w_obj), int(y + h_obj)), color, thickness)
                
                # Label v·ªõi emoji, class name, confidence v√† track_id
                label = f"{emoji} {obj_class}"
                if track_id is not None:
                    label += f" ID:{track_id}"
                label += f" {confidence:.2f}"
                
                # V·∫Ω label v·ªõi background ƒë·ªÉ d·ªÖ ƒë·ªçc
                (text_width, text_height), baseline = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, thickness
                )
                cv2.rectangle(annotated_frame, 
                             (int(x), int(y) - text_height - 10),
                             (int(x) + text_width, int(y)),
                             color, -1)  # Filled rectangle
                cv2.putText(annotated_frame, label, (int(x), int(y) - 5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), thickness)  # Black text
    
    # V·∫Ω status bar ·ªü tr√™n c√πng
    status_y = 20
    status_color = (0, 255, 0) if is_focusing else (0, 0, 255)
    status_text = "FOCUSING" if is_focusing else "NOT FOCUSING"
    cv2.rectangle(annotated_frame, (10, 5), (w - 10, 35), (0, 0, 0), -1)
    cv2.putText(annotated_frame, status_text, (20, 25),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
    
    # V·∫Ω th√¥ng tin attention
    info_y = 60
    if is_looking_at_adult:
        cv2.putText(annotated_frame, "Looking at Adult", (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        info_y += 25
    if is_looking_at_object:
        cv2.putText(annotated_frame, "Looking at Object", (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        info_y += 25
    
    # V·∫Ω frame count v√† time
    if fps > 0:
        time_sec = frame_count / fps
        time_text = f"Frame: {frame_count} | Time: {time_sec:.2f}s"
        cv2.putText(annotated_frame, time_text, (10, h - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # V·∫Ω h∆∞·ªõng d·∫´n d·ª´ng (·ªü g√≥c tr√™n b√™n ph·∫£i)
    stop_text = "Press 'q' or ESC to stop"
    text_size = cv2.getTextSize(stop_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
    text_x = w - text_size[0] - 10
    text_y = 25
    # Background cho text
    cv2.rectangle(annotated_frame, 
                 (text_x - 5, text_y - text_size[1] - 5),
                 (text_x + text_size[0] + 5, text_y + 5),
                 (0, 0, 0), -1)  # Black background
    cv2.putText(annotated_frame, stop_text, (text_x, text_y),
               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)  # Cyan text
    
    # V·∫Ω v·ªã tr√≠ gaze (gaze_x, gaze_y) n·∫øu c√≥
    if gaze_x is not None and gaze_y is not None:
        # Hi·ªÉn th·ªã gi√° tr·ªã gaze_x v√† gaze_y
        gaze_text = f"Gaze: X={gaze_x:.3f}, Y={gaze_y:.3f}"
        text_x = 10
        text_y = h - 40  # ·ªû tr√™n d√≤ng time
        
        # V·∫Ω background cho text ƒë·ªÉ d·ªÖ ƒë·ªçc
        (text_width, text_height), baseline = cv2.getTextSize(
            gaze_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )
        cv2.rectangle(annotated_frame, 
                     (text_x - 5, text_y - text_height - 5),
                     (text_x + text_width + 5, text_y + 5),
                     (0, 0, 0), -1)  # Black background
        
        # V·∫Ω text
        cv2.putText(annotated_frame, gaze_text, (text_x, text_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)  # Cyan color
        
        # V·∫Ω crosshair t·∫°i v·ªã tr√≠ gaze tr√™n frame (n·∫øu c√≥ child_face)
        if child_face is not None:
            if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
                x_face, y_face, w_face, h_face = child_face[:4]
                face_center_x = int(x_face + w_face / 2)
                face_center_y = int(y_face + h_face / 2)
            elif isinstance(child_face, dict):
                bbox = child_face.get('bbox', [])
                if len(bbox) >= 4:
                    x_face, y_face, w_face, h_face = bbox[:4]
                    face_center_x = int(x_face + w_face / 2)
                    face_center_y = int(y_face + h_face / 2)
                else:
                    face_center_x = w // 2
                    face_center_y = h // 2
            else:
                face_center_x = w // 2
                face_center_y = h // 2
            
            # T√≠nh v·ªã tr√≠ gaze tr√™n frame (t·ª´ normalized offset)
            # gaze_x v√† gaze_y l√† offset t·ª´ face center, t√≠nh theo frame size
            gaze_pixel_x = int(face_center_x + gaze_x * (w / 2))
            gaze_pixel_y = int(face_center_y + gaze_y * (h / 2))
            
            # ƒê·∫£m b·∫£o trong frame bounds
            gaze_pixel_x = max(0, min(w - 1, gaze_pixel_x))
            gaze_pixel_y = max(0, min(h - 1, gaze_pixel_y))
            
            # V·∫Ω crosshair (d·∫•u +) t·∫°i v·ªã tr√≠ gaze
            crosshair_size = 15
            crosshair_color = (0, 255, 255)  # Cyan
            crosshair_thickness = 2
            
            # V·∫Ω ƒë∆∞·ªùng ngang
            cv2.line(annotated_frame,
                    (gaze_pixel_x - crosshair_size, gaze_pixel_y),
                    (gaze_pixel_x + crosshair_size, gaze_pixel_y),
                    crosshair_color, crosshair_thickness)
            # V·∫Ω ƒë∆∞·ªùng d·ªçc
            cv2.line(annotated_frame,
                    (gaze_pixel_x, gaze_pixel_y - crosshair_size),
                    (gaze_pixel_x, gaze_pixel_y + crosshair_size),
                    crosshair_color, crosshair_thickness)
            
            # V·∫Ω ƒëi·ªÉm tr√≤n t·∫°i v·ªã tr√≠ gaze
            cv2.circle(annotated_frame, (gaze_pixel_x, gaze_pixel_y), 5, crosshair_color, -1)
            
            # V·∫Ω ƒë∆∞·ªùng n·ªëi t·ª´ face center ƒë·∫øn gaze position
            cv2.line(annotated_frame,
                    (face_center_x, face_center_y),
                    (gaze_pixel_x, gaze_pixel_y),
                    (255, 255, 0), 2)  # Yellow line
    
    # V·∫Ω h∆∞·ªõng quay ƒë·∫ßu (head rotation) n·∫øu c√≥
    if child_face is not None and head_pose is not None:
        if isinstance(child_face, (list, tuple)) and len(child_face) >= 4:
            x, y, w_face, h_face = child_face[:4]
            face_center_x = int(x + w_face / 2)
            face_center_y = int(y + h_face / 2)
        elif isinstance(child_face, dict):
            bbox = child_face.get('bbox', [])
            if len(bbox) >= 4:
                x, y, w_face, h_face = bbox[:4]
                face_center_x = int(x + w_face / 2)
                face_center_y = int(y + h_face / 2)
            else:
                face_center_x = w // 2
                face_center_y = h // 2
        else:
            face_center_x = w // 2
            face_center_y = h // 2
        
        try:
            yaw, pitch, roll = head_pose
            
            # Chuy·ªÉn ƒë·ªïi t·ª´ radians sang degrees ƒë·ªÉ hi·ªÉn th·ªã
            yaw_deg = np.degrees(yaw)
            pitch_deg = np.degrees(pitch)
            roll_deg = np.degrees(roll)
            
            # T√≠nh h∆∞·ªõng quay ƒë·∫ßu d·ª±a tr√™n yaw v√† pitch
            # Arrow length t·ª∑ l·ªá v·ªõi g√≥c quay
            max_angle = 30.0  # degrees
            arrow_length_base = 60
            
            # Yaw (left/right rotation)
            yaw_ratio = np.clip(abs(yaw_deg) / max_angle, 0, 1)
            yaw_arrow_length = int(arrow_length_base * yaw_ratio)
            if abs(yaw_deg) > 2:  # Ch·ªâ v·∫Ω n·∫øu quay ƒë√°ng k·ªÉ (>2 ƒë·ªô)
                if yaw_deg < 0:  # Quay tr√°i
                    yaw_end_x = face_center_x - yaw_arrow_length
                    yaw_end_y = face_center_y
                else:  # Quay ph·∫£i
                    yaw_end_x = face_center_x + yaw_arrow_length
                    yaw_end_y = face_center_y
                
                # V·∫Ω arrow cho yaw (m√†u ƒë·ªè)
                cv2.arrowedLine(annotated_frame, 
                               (face_center_x, face_center_y),
                               (yaw_end_x, yaw_end_y),
                               (0, 0, 255), 2, tipLength=0.3)
            
            # Pitch (up/down rotation)
            pitch_ratio = np.clip(abs(pitch_deg) / max_angle, 0, 1)
            pitch_arrow_length = int(arrow_length_base * pitch_ratio)
            if abs(pitch_deg) > 2:  # Ch·ªâ v·∫Ω n·∫øu quay ƒë√°ng k·ªÉ (>2 ƒë·ªô)
                if pitch_deg < 0:  # Quay l√™n
                    pitch_end_x = face_center_x
                    pitch_end_y = face_center_y - pitch_arrow_length
                else:  # Quay xu·ªëng
                    pitch_end_x = face_center_x
                    pitch_end_y = face_center_y + pitch_arrow_length
                
                # V·∫Ω arrow cho pitch (m√†u xanh l√°)
                cv2.arrowedLine(annotated_frame,
                               (face_center_x, face_center_y),
                               (pitch_end_x, pitch_end_y),
                               (0, 255, 0), 2, tipLength=0.3)
            
            # Hi·ªÉn th·ªã th√¥ng tin head pose
            head_pose_text = f"Head: Yaw={yaw_deg:.1f}¬∞ Pitch={pitch_deg:.1f}¬∞ Roll={roll_deg:.1f}¬∞"
            text_x = 10
            text_y = 90  # ·ªû d∆∞·ªõi gaze direction text
            
            # V·∫Ω background cho text
            (text_width, text_height), baseline = cv2.getTextSize(
                head_pose_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            cv2.rectangle(annotated_frame,
                         (text_x - 5, text_y - text_height - 5),
                         (text_x + text_width + 5, text_y + 5),
                         (0, 0, 0), -1)  # Black background
            
            # V·∫Ω text
            cv2.putText(annotated_frame, head_pose_text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)  # White color
            
            # V·∫Ω legend cho head rotation arrows
            legend_y = text_y + 25
            cv2.putText(annotated_frame, "Red: Yaw (L/R)", (text_x, legend_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            cv2.putText(annotated_frame, "Green: Pitch (U/D)", (text_x, legend_y + 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
        except (ValueError, TypeError) as e:
            # N·∫øu head_pose kh√¥ng ƒë√∫ng format, b·ªè qua
            pass
    
    # V·∫Ω variance v√† RMS distance n·∫øu c√≥
    stats_y = h - 70  # ·ªû tr√™n gaze text
    stats_texts = []
    
    if variance is not None:
        stats_texts.append(f"Variance: {variance:.6f}")
    
    if rms_distance is not None:
        stats_texts.append(f"RMS: {rms_distance:.6f}")
    
    if stats_texts:
        stats_text = " | ".join(stats_texts)
        text_x = 10
        
        # V·∫Ω background cho text
        (text_width, text_height), baseline = cv2.getTextSize(
            stats_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        cv2.rectangle(annotated_frame,
                     (text_x - 5, stats_y - text_height - 5),
                     (text_x + text_width + 5, stats_y + 5),
                     (0, 0, 0), -1)  # Black background
        
        # V·∫Ω text
        cv2.putText(annotated_frame, stats_text, (text_x, stats_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)  # Yellow color
    
    return annotated_frame
